{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ENL7UNlfjCj",
        "outputId": "035b270d-3f94-46fa-b4ab-7a1e89f912c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ufoZUFlKfjCu"
      },
      "outputs": [],
      "source": [
        "corpus=\"\"\" Hello I am Aditya Raj.\n",
        "I am a Data Scientist.\n",
        "Currrently I am learning Natural Language Processing\n",
        "Want to work in Natural Language Processing\n",
        "Aditya'sssss\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJeLg9dAfjCu",
        "outputId": "9ee9765d-686c-44ee-aca4-6d331567d74c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Hello I am Aditya Raj.\n",
            "I am a Data Scientist. \n",
            "Currrently I am learning Natural Language Processing\n",
            "Want to work in Natural Language Processing\n",
            "Aditya'sssss\n"
          ]
        }
      ],
      "source": [
        "print(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "hqfeD5FzfjCu"
      },
      "outputs": [],
      "source": [
        "##  Tokenization\n",
        "## Sentence-->paragraphs\n",
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "# Download the punkt tokenizer for sentence splitting\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efGmCtkKgUuw",
        "outputId": "5fadb151-d684-4aa3-ba2c-9dc39cddc44e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "yC60TLkbfjCv"
      },
      "outputs": [],
      "source": [
        "documents=sent_tokenize(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YBeBhrYggvh",
        "outputId": "60d62e17-a5a0-47d6-fc3a-bbe416e41dba"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' Hello I am Aditya Raj.', 'I am a Data Scientist.', \"Currrently I am learning Natural Language Processing\\nWant to work in Natural Language Processing\\nAditya'sssss\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsX5SHHNfjCv",
        "outputId": "da02b716-aef4-41e0-9ff5-d55665930dc5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "type(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5US_pRlfjCv",
        "outputId": "6ea55869-79fb-4425-d6b6-878f705e1ef9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Hello I am Aditya Raj.\n",
            "I am a Data Scientist.\n",
            "Currrently I am learning Natural Language Processing\n",
            "Want to work in Natural Language Processing\n",
            "Aditya'sssss\n"
          ]
        }
      ],
      "source": [
        "for sentence in documents:\n",
        "    print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "HOXDRx76fjCv"
      },
      "outputs": [],
      "source": [
        "## Tokenization\n",
        "## Paragraph-->words\n",
        "## sentence--->words\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz4Xry_vfjCv",
        "outputId": "22fb5558-061c-4832-a4ea-42e3ea511a63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello',\n",
              " 'I',\n",
              " 'am',\n",
              " 'Aditya',\n",
              " 'Raj',\n",
              " '.',\n",
              " 'I',\n",
              " 'am',\n",
              " 'a',\n",
              " 'Data',\n",
              " 'Scientist',\n",
              " '.',\n",
              " 'Currrently',\n",
              " 'I',\n",
              " 'am',\n",
              " 'learning',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " 'Want',\n",
              " 'to',\n",
              " 'work',\n",
              " 'in',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " \"Aditya'sssss\"]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "word_tokenize(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVKl9_-ZfjCv",
        "outputId": "4726c636-ba4b-452e-e8da-65263f987b50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'I', 'am', 'Aditya', 'Raj', '.']\n",
            "['I', 'am', 'a', 'Data', 'Scientist', '.']\n",
            "['Currrently', 'I', 'am', 'learning', 'Natural', 'Language', 'Processing', 'Want', 'to', 'work', 'in', 'Natural', 'Language', 'Processing', \"Aditya'sssss\"]\n"
          ]
        }
      ],
      "source": [
        "for sentence in documents:\n",
        "    print(word_tokenize(sentence))##directly applying word tokenize on sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "-VPd5G7LfjCw"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import wordpunct_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oeeahp0fjCw",
        "outputId": "4d2af608-468f-4b36-e81b-57ff8cbcfa9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello',\n",
              " 'I',\n",
              " 'am',\n",
              " 'Aditya',\n",
              " 'Raj',\n",
              " '.',\n",
              " 'I',\n",
              " 'am',\n",
              " 'a',\n",
              " 'Data',\n",
              " 'Scientist',\n",
              " '.',\n",
              " 'Currrently',\n",
              " 'I',\n",
              " 'am',\n",
              " 'learning',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " 'Want',\n",
              " 'to',\n",
              " 'work',\n",
              " 'in',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " 'Aditya',\n",
              " \"'\",\n",
              " 'sssss']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "wordpunct_tokenize(corpus)# now 'sssss is also got split\n",
        "##it make sure that punctuation can also be treated as separate word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "0jaL8lW7fjCw"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "7YiKz3UUfjCw"
      },
      "outputs": [],
      "source": [
        "tokenizer=TreebankWordTokenizer()##middle full stop is not consdier whereas end full stop is considered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-hNVZr1fjCw",
        "outputId": "a6bc837f-91e6-4318-8981-4268798dc9c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello',\n",
              " 'I',\n",
              " 'am',\n",
              " 'Aditya',\n",
              " 'Raj.',\n",
              " 'I',\n",
              " 'am',\n",
              " 'a',\n",
              " 'Data',\n",
              " 'Scientist.',\n",
              " 'Currrently',\n",
              " 'I',\n",
              " 'am',\n",
              " 'learning',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " 'Want',\n",
              " 'to',\n",
              " 'work',\n",
              " 'in',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " \"Aditya'sssss\"]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "tokenizer.tokenize(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqGKJ3bNfjCw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRe9ERGVfjCw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q56FUw2tfjCw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}